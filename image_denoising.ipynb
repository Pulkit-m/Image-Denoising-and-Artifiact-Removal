{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRequirements: \\n* One Generate Patches script to take in dataset and make patches out of them and store them into designated location in datasets folder\\n* train test split\\n* One dataloader for training and one dataloader for testing.\\n\\n* Construct the Unet Model. Take care of input size, take care that you may need to incorporate grid and inverse grid function later.\\n    * Unet model should have functionalities: \\n      * Feed data \\n      * ... all functionalities as available in image restoration model. But make it only essential.\\n\\n* Write a training script as well. \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Requirements: \n",
    "* One Generate Patches script to take in dataset and make patches out of them and store them into designated location in datasets folder\n",
    "* train test split\n",
    "* One dataloader for training and one dataloader for testing.\n",
    "\n",
    "* Construct the Unet Model. Take care of input size, take care that you may need to incorporate grid and inverse grid function later.\n",
    "    * Unet model should have functionalities: \n",
    "      * Feed data \n",
    "      * ... all functionalities as available in image restoration model. But make it only essential.\n",
    "\n",
    "* Write a training script as well. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import random \n",
    "import os \n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_images = './datasets/raw/Train/LR_x4/' \n",
    "HR_images = './datasets/raw/Train/HR/'\n",
    "SR_images = './datasets/raw/Train/SR/'\n",
    "\n",
    "if not os.path.exists('./datasets/patches/'): \n",
    "    os.makedirs('./datasets/patches') \n",
    "    os.makedirs('./datasets/patches/HR')\n",
    "    os.makedirs('./datasets/patches/SR') \n",
    "else: \n",
    "    print(\"patches Already present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6945ccc68e341a6a3437ff879695583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crop_h, crop_w = 256, 256\n",
    "stride = 100 \n",
    "\n",
    "N_T = len(os.listdir(HR_images))//2 \n",
    "patches_hr = './datasets/patches/HR'\n",
    "patches_sr = './datasets/patches/SR'\n",
    "\n",
    "img_fmt = '0000{}_{}.png'\n",
    "idx_patch = 1 \n",
    "folder_name_fmt = '000000{}'\n",
    "for i in tqdm(range(1, N_T+1)): \n",
    "    limg, rimg = img_fmt.format(i,'L'), img_fmt.format(i,'R') \n",
    "    limg, rimg = limg[-10:], rimg[-10:]\n",
    "    hr_l = cv2.imread(os.path.join(HR_images,limg)) \n",
    "    hr_r = cv2.imread(os.path.join(HR_images,rimg))  \n",
    "\n",
    "    sr_l = cv2.imread(os.path.join(SR_images,limg)) \n",
    "    sr_r = cv2.imread(os.path.join(SR_images,rimg)) \n",
    "\n",
    "    # print(limg, rimg, '\\r') \n",
    "    H = hr_l.shape[0] \n",
    "    W = hr_l.shape[1]\n",
    "\n",
    "    for y in range(0, H-crop_h+1, stride):  \n",
    "        for x in range(0, W-crop_w+1, stride): \n",
    "            patch_hr_l = hr_l[y:y+crop_h, x:x+crop_w] \n",
    "            patch_hr_r = hr_r[y:y+crop_h, x:x+crop_w]\n",
    "            dest_folder = os.path.join(patches_hr, folder_name_fmt.format(idx_patch)[-6:])\n",
    "            os.makedirs(dest_folder, exist_ok=True)\n",
    "            cv2.imwrite(os.path.join(dest_folder,'hr_l.png'), patch_hr_l)\n",
    "            cv2.imwrite(os.path.join(dest_folder,'hr_r.png'), patch_hr_r)\n",
    "\n",
    "            patch_sr_l = sr_l[y:y+crop_h, x:x+crop_w]\n",
    "            patch_sr_r = sr_r[y:y+crop_h, x:x+crop_w]\n",
    "            dest_folder = os.path.join(patches_sr, folder_name_fmt.format(idx_patch)[-6:]) \n",
    "            os.makedirs(dest_folder, exist_ok=True) \n",
    "            cv2.imwrite(os.path.join(dest_folder,'sr_l.png'), patch_sr_l)\n",
    "            cv2.imwrite(os.path.join(dest_folder,'sr_r.png'), patch_sr_r)\n",
    "\n",
    "\n",
    "            idx_patch += 1\n",
    "\n",
    "\n",
    "    # break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset \n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m      5\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCustomLoader\u001b[39;00m(Dataset): \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from torch.utils.data import Dataset \n",
    "from PIL import Image\n",
    "\n",
    "class CustomLoader(Dataset): \n",
    "    def __init__(self, hr_dir, sr_dir, list_idxs, transform = None):\n",
    "        \"\"\"\n",
    "        returns hr_l, hr_r, sr_l, sr_r\n",
    "        \"\"\"\n",
    "        self.hr_dir, self.sr_dir = hr_dir , sr_dir \n",
    "        self.list_idxs = list_idxs \n",
    "        N = len(list_idxs)\n",
    "        self.idx_map = {i:list_idxs[i] for i in range(N)} \n",
    "        self.folder_name = '000000{}'.format(idx)[-6:]\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.list_idxs)\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        idx = self.idx_map[index] \n",
    "         \n",
    "\n",
    "        hr_l = os.path.join(self.hr_dir,self.folder_name,'hr_l.png')\n",
    "        hr_r = os.path.join(self.hr_dir,self.folder_name,'hr_r.png')\n",
    "        hr_l = np.array(Image.open(hr_l).convert(\"RGB\")) \n",
    "        hr_r = np.array(Image.open(hr_r).convert(\"RGB\"))\n",
    "\n",
    "        sr_l = os.path.join(self.sr_dir,self.folder_name,'sr_l.png') \n",
    "        sr_r = os.path.join(self.sr_dir,self.folder_name,'sr_r.png')\n",
    "        sr_l = np.array(Image.open(sr_l).convert(\"RGB\"))\n",
    "        sr_r = np.array(Image.open(sr_r).convert(\"RGB\"))\n",
    "\n",
    "        if self.transform is not None: \n",
    "            pass \n",
    "\n",
    "        return (hr_l,hr_r,sr_l,sr_r)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('ssr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74b3fe91d04464841c443b319d726e4457066d551ffc429180ae4cbbfa1d40db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
